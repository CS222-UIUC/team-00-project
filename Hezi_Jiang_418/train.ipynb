{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c54363e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_dataset(source_dir, train_dir, test_dir, test_ratio=0.2):\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for class_name in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        images = os.listdir(class_path)\n",
    "        random.shuffle(images)\n",
    "\n",
    "        split_idx = int(len(images) * (1 - test_ratio))\n",
    "        train_images = images[:split_idx]\n",
    "        test_images = images[split_idx:]\n",
    "\n",
    "        train_class_dir = os.path.join(train_dir, class_name)\n",
    "        test_class_dir = os.path.join(test_dir, class_name)\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "        for img in train_images:\n",
    "            shutil.copy(os.path.join(class_path, img), os.path.join(train_class_dir, img))\n",
    "        for img in test_images:\n",
    "            shutil.copy(os.path.join(class_path, img), os.path.join(test_class_dir, img))\n",
    "\n",
    "split_dataset(\"/home/u/CS 411/archive\", \"dataset/train\", \"dataset/test\", test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e0877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6044815007816571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.19      0.79      0.31        19\n",
      "           0       0.75      0.95      0.84       928\n",
      "           2       0.51      0.76      0.61       671\n",
      "           3       0.73      0.84      0.78       603\n",
      "           4       0.52      0.49      0.51       416\n",
      "           5       0.65      0.67      0.66       260\n",
      "           6       0.86      0.83      0.85       432\n",
      "           7       0.72      0.54      0.62       448\n",
      "           8       0.95      0.56      0.70       396\n",
      "           9       0.81      0.62      0.70       447\n",
      "           B       0.62      0.73      0.67       404\n",
      "       Delta       0.78      0.74      0.76        19\n",
      "           E       0.70      0.56      0.62       112\n",
      "           R       0.56      0.48      0.52       262\n",
      "           a       0.85      0.79      0.82      1220\n",
      "       alpha       0.81      0.79      0.80       409\n",
      "        beta       0.84      0.57      0.68       114\n",
      "     bracket       0.53      0.51      0.52      3734\n",
      "         cos       1.00      0.59      0.74       162\n",
      "           d       0.75      0.65      0.70       173\n",
      "         div       0.77      0.23      0.35       119\n",
      "           f       0.65      0.30      0.41       186\n",
      "      forall       0.80      0.50      0.62         8\n",
      "           g       0.79      0.25      0.38       146\n",
      "       gamma       0.80      0.41      0.55        29\n",
      "         geq       0.47      0.57      0.52        28\n",
      "           h       0.46      0.21      0.29        63\n",
      "           i       0.72      0.35      0.47       588\n",
      "          in       1.00      0.40      0.57        15\n",
      "       infty       1.00      0.40      0.57        88\n",
      "         int       0.33      0.16      0.21       101\n",
      "           k       0.71      0.33      0.45       163\n",
      "         leq       1.00      0.49      0.66        73\n",
      "         lim       0.90      0.37      0.53        70\n",
      "         log       1.00      0.49      0.65       105\n",
      "          lt       0.50      0.13      0.21        15\n",
      "           m       0.80      0.33      0.47        84\n",
      "          mu       1.00      0.33      0.50        15\n",
      "           n       0.21      0.75      0.33      1116\n",
      "         neq       0.93      0.56      0.70        25\n",
      "           o       1.00      0.08      0.14        26\n",
      "           p       0.73      0.49      0.59       170\n",
      "         phi       1.00      0.33      0.50        21\n",
      "          pi       1.00      0.30      0.46       115\n",
      "          pm       0.98      0.47      0.63       103\n",
      "           q       0.83      0.27      0.40        90\n",
      "           s       0.76      0.55      0.64       155\n",
      "       sigma       0.00      0.00      0.00         4\n",
      "         sin       0.98      0.60      0.75       210\n",
      "        sqrt       0.96      0.85      0.90       645\n",
      "         sum       1.00      0.41      0.59       133\n",
      "           t       0.66      0.17      0.26       321\n",
      "         tan       1.00      0.35      0.52        34\n",
      "       theta       0.97      0.31      0.47       121\n",
      "       times       0.86      0.76      0.81       625\n",
      "           u       0.78      0.47      0.59       194\n",
      "           v       0.83      0.43      0.56        89\n",
      "           w       0.89      0.29      0.43        28\n",
      "           x       0.90      0.63      0.74      1070\n",
      "           y       0.83      0.45      0.58       372\n",
      "           z       0.88      0.51      0.65       398\n",
      "\n",
      "    accuracy                           0.60     19190\n",
      "   macro avg       0.77      0.49      0.56     19190\n",
      "weighted avg       0.70      0.60      0.62     19190\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/u/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/u/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def load_images_from_folder(folder, image_size=(28, 28)):\n",
    "    X, y = [], []\n",
    "    for label in os.listdir(folder):\n",
    "        label_path = os.path.join(folder, label)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "        for filename in os.listdir(label_path):\n",
    "            img_path = os.path.join(label_path, filename)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('L')\n",
    "                img = img.resize(image_size)\n",
    "                img_array = np.array(img).flatten()\n",
    "                X.append(img_array)\n",
    "                y.append(label)\n",
    "            except:\n",
    "                continue\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = load_images_from_folder(\"dataset/train\")\n",
    "X_test, y_test = load_images_from_folder(\"dataset/test\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6757d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.861490359562272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.00      0.00      0.00        19\n",
      "           0       0.95      0.99      0.97       928\n",
      "           2       0.85      0.88      0.86       671\n",
      "           3       0.93      0.93      0.93       603\n",
      "           4       0.81      0.57      0.67       416\n",
      "           5       0.85      0.80      0.82       260\n",
      "           6       0.99      0.98      0.98       432\n",
      "           7       0.97      0.66      0.78       448\n",
      "           8       0.98      0.97      0.98       396\n",
      "           9       0.94      0.95      0.94       447\n",
      "           B       0.93      0.84      0.88       404\n",
      "       Delta       1.00      0.89      0.94        19\n",
      "           E       0.91      0.82      0.86       112\n",
      "           R       0.93      0.78      0.85       262\n",
      "           a       0.96      0.97      0.96      1220\n",
      "       alpha       0.94      0.93      0.93       409\n",
      "        beta       1.00      0.97      0.99       114\n",
      "     bracket       0.69      1.00      0.81      3734\n",
      "         cos       1.00      1.00      1.00       162\n",
      "           d       0.96      0.88      0.92       173\n",
      "         div       1.00      0.29      0.45       119\n",
      "           f       0.99      0.49      0.65       186\n",
      "      forall       1.00      0.50      0.67         8\n",
      "           g       1.00      0.74      0.85       146\n",
      "       gamma       1.00      0.62      0.77        29\n",
      "         geq       1.00      0.79      0.88        28\n",
      "           h       1.00      0.35      0.52        63\n",
      "           i       0.85      0.18      0.29       588\n",
      "          in       1.00      0.87      0.93        15\n",
      "       infty       1.00      0.99      0.99        88\n",
      "         int       0.00      0.00      0.00       101\n",
      "           k       0.89      0.91      0.90       163\n",
      "         leq       1.00      0.90      0.95        73\n",
      "         lim       1.00      0.86      0.92        70\n",
      "         log       0.99      0.96      0.98       105\n",
      "          lt       1.00      0.73      0.85        15\n",
      "           m       1.00      0.75      0.86        84\n",
      "          mu       1.00      0.87      0.93        15\n",
      "           n       0.95      0.96      0.95      1116\n",
      "         neq       1.00      0.88      0.94        25\n",
      "           o       0.00      0.00      0.00        26\n",
      "           p       0.95      0.85      0.90       170\n",
      "         phi       1.00      0.95      0.98        21\n",
      "          pi       1.00      0.86      0.93       115\n",
      "          pm       1.00      0.70      0.82       103\n",
      "           q       0.96      0.84      0.90        90\n",
      "           s       0.89      0.59      0.71       155\n",
      "       sigma       0.00      0.00      0.00         4\n",
      "         sin       0.95      0.97      0.96       210\n",
      "        sqrt       0.99      0.88      0.94       645\n",
      "         sum       0.99      0.92      0.96       133\n",
      "           t       0.93      0.31      0.47       321\n",
      "         tan       1.00      0.74      0.85        34\n",
      "       theta       0.99      0.92      0.95       121\n",
      "       times       0.95      0.82      0.88       625\n",
      "           u       0.99      0.84      0.91       194\n",
      "           v       0.91      0.83      0.87        89\n",
      "           w       1.00      0.96      0.98        28\n",
      "           x       0.80      0.96      0.87      1070\n",
      "           y       0.91      0.87      0.89       372\n",
      "           z       0.98      0.74      0.84       398\n",
      "\n",
      "    accuracy                           0.86     19190\n",
      "   macro avg       0.89      0.75      0.80     19190\n",
      "weighted avg       0.88      0.86      0.85     19190\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/u/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/u/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a41f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9328295987493486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042bfb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 2.3000, Accuracy = 45.07%\n",
      "Epoch 2: Loss = 1.5035, Accuracy = 62.97%\n",
      "Epoch 3: Loss = 1.2900, Accuracy = 68.06%\n",
      "Epoch 4: Loss = 1.1526, Accuracy = 71.65%\n",
      "Epoch 5: Loss = 1.0480, Accuracy = 74.03%\n",
      "Epoch 6: Loss = 0.9727, Accuracy = 76.00%\n",
      "Epoch 7: Loss = 0.9105, Accuracy = 77.54%\n",
      "Epoch 8: Loss = 0.8669, Accuracy = 78.64%\n",
      "Epoch 9: Loss = 0.8283, Accuracy = 79.44%\n",
      "Epoch 10: Loss = 0.8001, Accuracy = 80.19%\n",
      "Epoch 11: Loss = 0.7685, Accuracy = 81.07%\n",
      "Epoch 12: Loss = 0.7498, Accuracy = 81.60%\n",
      "Epoch 13: Loss = 0.7253, Accuracy = 82.08%\n",
      "Epoch 14: Loss = 0.7090, Accuracy = 82.46%\n",
      "Epoch 15: Loss = 0.6911, Accuracy = 82.94%\n",
      "Epoch 16: Loss = 0.6760, Accuracy = 83.29%\n",
      "Epoch 17: Loss = 0.6638, Accuracy = 83.66%\n",
      "Epoch 18: Loss = 0.6481, Accuracy = 83.86%\n",
      "Epoch 19: Loss = 0.6370, Accuracy = 84.24%\n",
      "Epoch 20: Loss = 0.6273, Accuracy = 84.37%\n",
      "Epoch 21: Loss = 0.6158, Accuracy = 84.59%\n",
      "Epoch 22: Loss = 0.6100, Accuracy = 84.94%\n",
      "Epoch 23: Loss = 0.5969, Accuracy = 85.09%\n",
      "Epoch 24: Loss = 0.5841, Accuracy = 85.45%\n",
      "Epoch 25: Loss = 0.5779, Accuracy = 85.57%\n",
      "Epoch 26: Loss = 0.5699, Accuracy = 85.75%\n",
      "Epoch 27: Loss = 0.5612, Accuracy = 86.06%\n",
      "Epoch 28: Loss = 0.5548, Accuracy = 86.23%\n",
      "Epoch 29: Loss = 0.5476, Accuracy = 86.30%\n",
      "Epoch 30: Loss = 0.5401, Accuracy = 86.52%\n",
      "Epoch 31: Loss = 0.5323, Accuracy = 86.70%\n",
      "Epoch 32: Loss = 0.5271, Accuracy = 86.91%\n",
      "Epoch 33: Loss = 0.5176, Accuracy = 87.06%\n",
      "Epoch 34: Loss = 0.5110, Accuracy = 87.41%\n",
      "Epoch 35: Loss = 0.5082, Accuracy = 87.42%\n",
      "Epoch 36: Loss = 0.5038, Accuracy = 87.44%\n",
      "Epoch 37: Loss = 0.4936, Accuracy = 87.66%\n",
      "Epoch 38: Loss = 0.4916, Accuracy = 87.76%\n",
      "Epoch 39: Loss = 0.4816, Accuracy = 88.03%\n",
      "Epoch 40: Loss = 0.4827, Accuracy = 88.05%\n",
      "Epoch 41: Loss = 0.4750, Accuracy = 88.24%\n",
      "Epoch 42: Loss = 0.4676, Accuracy = 88.41%\n",
      "Epoch 43: Loss = 0.4668, Accuracy = 88.43%\n",
      "Epoch 44: Loss = 0.4617, Accuracy = 88.58%\n",
      "Epoch 45: Loss = 0.4569, Accuracy = 88.69%\n",
      "Epoch 46: Loss = 0.4524, Accuracy = 88.96%\n",
      "Epoch 47: Loss = 0.4493, Accuracy = 88.90%\n",
      "Epoch 48: Loss = 0.4477, Accuracy = 89.02%\n",
      "Epoch 49: Loss = 0.4417, Accuracy = 89.20%\n",
      "Epoch 50: Loss = 0.4360, Accuracy = 89.26%\n",
      "Epoch 51: Loss = 0.4341, Accuracy = 89.39%\n",
      "Epoch 52: Loss = 0.4332, Accuracy = 89.41%\n",
      "Epoch 53: Loss = 0.4274, Accuracy = 89.58%\n",
      "Epoch 54: Loss = 0.4278, Accuracy = 89.53%\n",
      "Epoch 55: Loss = 0.4213, Accuracy = 89.66%\n",
      "Epoch 56: Loss = 0.4167, Accuracy = 89.76%\n",
      "Epoch 57: Loss = 0.4120, Accuracy = 89.97%\n",
      "Epoch 58: Loss = 0.4135, Accuracy = 89.84%\n",
      "Epoch 59: Loss = 0.4117, Accuracy = 89.94%\n",
      "Epoch 60: Loss = 0.4039, Accuracy = 90.24%\n",
      "Epoch 61: Loss = 0.4031, Accuracy = 90.24%\n",
      "Epoch 62: Loss = 0.4052, Accuracy = 90.07%\n",
      "Epoch 63: Loss = 0.3954, Accuracy = 90.37%\n",
      "Epoch 64: Loss = 0.4003, Accuracy = 90.20%\n",
      "Epoch 65: Loss = 0.3941, Accuracy = 90.52%\n",
      "Epoch 66: Loss = 0.3931, Accuracy = 90.45%\n",
      "Epoch 67: Loss = 0.3905, Accuracy = 90.58%\n",
      "Epoch 68: Loss = 0.3895, Accuracy = 90.55%\n",
      "Epoch 69: Loss = 0.3839, Accuracy = 90.82%\n",
      "Epoch 70: Loss = 0.3831, Accuracy = 90.89%\n",
      "Epoch 71: Loss = 0.3847, Accuracy = 90.75%\n",
      "Epoch 72: Loss = 0.3790, Accuracy = 90.97%\n",
      "Epoch 73: Loss = 0.3753, Accuracy = 91.02%\n",
      "Epoch 74: Loss = 0.3797, Accuracy = 90.90%\n",
      "Epoch 75: Loss = 0.3740, Accuracy = 91.17%\n",
      "Epoch 76: Loss = 0.3704, Accuracy = 91.20%\n",
      "Epoch 77: Loss = 0.3697, Accuracy = 91.20%\n",
      "Epoch 78: Loss = 0.3650, Accuracy = 91.43%\n",
      "Epoch 79: Loss = 0.3677, Accuracy = 91.34%\n",
      "Epoch 80: Loss = 0.3670, Accuracy = 91.37%\n",
      "Epoch 81: Loss = 0.3619, Accuracy = 91.44%\n",
      "Epoch 82: Loss = 0.3591, Accuracy = 91.67%\n",
      "Epoch 83: Loss = 0.3605, Accuracy = 91.48%\n",
      "Epoch 84: Loss = 0.3676, Accuracy = 91.27%\n",
      "Epoch 85: Loss = 0.3520, Accuracy = 91.88%\n",
      "Epoch 86: Loss = 0.3571, Accuracy = 91.65%\n",
      "Epoch 87: Loss = 0.3534, Accuracy = 91.71%\n",
      "Epoch 88: Loss = 0.3526, Accuracy = 91.80%\n",
      "Epoch 89: Loss = 0.3563, Accuracy = 91.62%\n",
      "Epoch 90: Loss = 0.3499, Accuracy = 91.94%\n",
      "Epoch 91: Loss = 0.3542, Accuracy = 91.68%\n",
      "Epoch 92: Loss = 0.3486, Accuracy = 91.91%\n",
      "Epoch 93: Loss = 0.3435, Accuracy = 92.14%\n",
      "Epoch 94: Loss = 0.3502, Accuracy = 91.91%\n",
      "Epoch 95: Loss = 0.3473, Accuracy = 91.94%\n",
      "Epoch 96: Loss = 0.3523, Accuracy = 91.75%\n",
      "Epoch 97: Loss = 0.3392, Accuracy = 92.22%\n",
      "Epoch 98: Loss = 0.3383, Accuracy = 92.24%\n",
      "Epoch 99: Loss = 0.3427, Accuracy = 92.10%\n",
      "Epoch 100: Loss = 0.3464, Accuracy = 91.93%\n",
      "Epoch 101: Loss = 0.3389, Accuracy = 92.23%\n",
      "Epoch 102: Loss = 0.3411, Accuracy = 92.16%\n",
      "Epoch 103: Loss = 0.3390, Accuracy = 92.18%\n",
      "Epoch 104: Loss = 0.3396, Accuracy = 92.19%\n",
      "Epoch 105: Loss = 0.3441, Accuracy = 92.10%\n",
      "Epoch 106: Loss = 0.3348, Accuracy = 92.38%\n",
      "Epoch 107: Loss = 0.3298, Accuracy = 92.58%\n",
      "Epoch 108: Loss = 0.3383, Accuracy = 92.23%\n",
      "Epoch 109: Loss = 0.3409, Accuracy = 92.20%\n",
      "Epoch 110: Loss = 0.3370, Accuracy = 92.37%\n",
      "Epoch 111: Loss = 0.3319, Accuracy = 92.42%\n",
      "Epoch 112: Loss = 0.3256, Accuracy = 92.74%\n",
      "Epoch 113: Loss = 0.3337, Accuracy = 92.40%\n",
      "Epoch 114: Loss = 0.3365, Accuracy = 92.29%\n",
      "Epoch 115: Loss = 0.3293, Accuracy = 92.63%\n",
      "Epoch 116: Loss = 0.3332, Accuracy = 92.43%\n",
      "Epoch 117: Loss = 0.3329, Accuracy = 92.41%\n",
      "Epoch 118: Loss = 0.3302, Accuracy = 92.57%\n",
      "Epoch 119: Loss = 0.3270, Accuracy = 92.71%\n",
      "Epoch 120: Loss = 0.3311, Accuracy = 92.53%\n",
      "Epoch 121: Loss = 0.3228, Accuracy = 92.78%\n",
      "Epoch 122: Loss = 0.3239, Accuracy = 92.76%\n",
      "Epoch 123: Loss = 0.3322, Accuracy = 92.42%\n",
      "Epoch 124: Loss = 0.3221, Accuracy = 92.80%\n",
      "Epoch 125: Loss = 0.3286, Accuracy = 92.61%\n",
      "Epoch 126: Loss = 0.3248, Accuracy = 92.74%\n",
      "Epoch 127: Loss = 0.3288, Accuracy = 92.62%\n",
      "Epoch 128: Loss = 0.3245, Accuracy = 92.73%\n",
      "Epoch 129: Loss = 0.3228, Accuracy = 92.83%\n",
      "Epoch 130: Loss = 0.3183, Accuracy = 92.97%\n",
      "Epoch 131: Loss = 0.3298, Accuracy = 92.58%\n",
      "Epoch 132: Loss = 0.3225, Accuracy = 92.75%\n",
      "Epoch 133: Loss = 0.3209, Accuracy = 92.86%\n",
      "Epoch 134: Loss = 0.3248, Accuracy = 92.76%\n",
      "Epoch 135: Loss = 0.3194, Accuracy = 92.93%\n",
      "Epoch 136: Loss = 0.3238, Accuracy = 92.74%\n",
      "Epoch 137: Loss = 0.3152, Accuracy = 93.06%\n",
      "Epoch 138: Loss = 0.3206, Accuracy = 92.90%\n",
      "Epoch 139: Loss = 0.3199, Accuracy = 92.86%\n",
      "Epoch 140: Loss = 0.3280, Accuracy = 92.58%\n",
      "Epoch 141: Loss = 0.3232, Accuracy = 92.79%\n",
      "Epoch 142: Loss = 0.3123, Accuracy = 93.21%\n",
      "Epoch 143: Loss = 0.3141, Accuracy = 93.07%\n",
      "Epoch 144: Loss = 0.3155, Accuracy = 93.09%\n",
      "Epoch 145: Loss = 0.3205, Accuracy = 92.86%\n",
      "Epoch 146: Loss = 0.3204, Accuracy = 92.91%\n",
      "Epoch 147: Loss = 0.3183, Accuracy = 92.91%\n",
      "Epoch 148: Loss = 0.3201, Accuracy = 92.93%\n",
      "Epoch 149: Loss = 0.3186, Accuracy = 92.90%\n",
      "Epoch 150: Loss = 0.3202, Accuracy = 92.85%\n",
      "Epoch 151: Loss = 0.3072, Accuracy = 93.35%\n",
      "Epoch 152: Loss = 0.3135, Accuracy = 93.08%\n",
      "Epoch 153: Loss = 0.3352, Accuracy = 92.47%\n",
      "Epoch 154: Loss = 0.3095, Accuracy = 93.23%\n",
      "Epoch 155: Loss = 0.3055, Accuracy = 93.37%\n",
      "Epoch 156: Loss = 0.3201, Accuracy = 92.89%\n",
      "Epoch 157: Loss = 0.3183, Accuracy = 92.89%\n",
      "Epoch 158: Loss = 0.3088, Accuracy = 93.20%\n",
      "Epoch 159: Loss = 0.3229, Accuracy = 92.79%\n",
      "Epoch 160: Loss = 0.3091, Accuracy = 93.23%\n",
      "Epoch 161: Loss = 0.3119, Accuracy = 93.10%\n",
      "Epoch 162: Loss = 0.3083, Accuracy = 93.25%\n",
      "Epoch 163: Loss = 0.3075, Accuracy = 93.32%\n",
      "Epoch 164: Loss = 0.3257, Accuracy = 92.63%\n",
      "Epoch 165: Loss = 0.3104, Accuracy = 93.22%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     48\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     50\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     51\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/folder.py:232\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    230\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 94\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    170\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(), \n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder('dataset/train', transform=transform)\n",
    "test_data = datasets.ImageFolder('dataset/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(num_classes=len(train_data.classes)).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss = criterion(model(images), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader.dataset)\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}, Accuracy = {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b15ec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet Epoch 1: Loss = 1.3846, Accuracy = 66.66%\n",
      "ResNet Epoch 2: Loss = 0.7807, Accuracy = 80.14%\n",
      "ResNet Epoch 3: Loss = 0.6406, Accuracy = 83.54%\n",
      "ResNet Epoch 4: Loss = 0.5634, Accuracy = 85.56%\n",
      "ResNet Epoch 5: Loss = 0.5169, Accuracy = 86.76%\n",
      "ResNet Epoch 6: Loss = 0.4822, Accuracy = 87.82%\n",
      "ResNet Epoch 7: Loss = 0.4543, Accuracy = 88.68%\n",
      "ResNet Epoch 8: Loss = 0.4383, Accuracy = 88.89%\n",
      "ResNet Epoch 9: Loss = 0.4209, Accuracy = 89.47%\n",
      "ResNet Epoch 10: Loss = 0.4042, Accuracy = 89.96%\n",
      "ResNet Epoch 11: Loss = 0.3957, Accuracy = 90.18%\n",
      "ResNet Epoch 12: Loss = 0.3796, Accuracy = 90.71%\n",
      "ResNet Epoch 13: Loss = 0.3732, Accuracy = 90.79%\n",
      "ResNet Epoch 14: Loss = 0.3700, Accuracy = 91.03%\n",
      "ResNet Epoch 15: Loss = 0.3650, Accuracy = 91.21%\n",
      "ResNet Epoch 16: Loss = 0.3503, Accuracy = 91.60%\n",
      "ResNet Epoch 17: Loss = 0.3565, Accuracy = 91.33%\n",
      "ResNet Epoch 18: Loss = 0.3478, Accuracy = 91.75%\n",
      "ResNet Epoch 19: Loss = 0.3384, Accuracy = 92.06%\n",
      "ResNet Epoch 20: Loss = 0.3350, Accuracy = 92.13%\n",
      "ResNet Epoch 21: Loss = 0.3344, Accuracy = 92.12%\n",
      "ResNet Epoch 22: Loss = 0.3346, Accuracy = 92.08%\n",
      "ResNet Epoch 23: Loss = 0.3268, Accuracy = 92.30%\n",
      "ResNet Epoch 24: Loss = 0.3234, Accuracy = 92.54%\n",
      "ResNet Epoch 25: Loss = 0.3283, Accuracy = 92.41%\n",
      "ResNet Epoch 26: Loss = 0.3216, Accuracy = 92.46%\n",
      "ResNet Epoch 27: Loss = 0.3131, Accuracy = 92.90%\n",
      "ResNet Epoch 28: Loss = 0.3155, Accuracy = 92.75%\n",
      "ResNet Epoch 29: Loss = 0.3137, Accuracy = 92.85%\n",
      "ResNet Epoch 30: Loss = 0.3105, Accuracy = 92.93%\n",
      "ResNet Epoch 31: Loss = 0.3047, Accuracy = 93.19%\n",
      "ResNet Epoch 32: Loss = 0.3144, Accuracy = 92.95%\n",
      "ResNet Epoch 33: Loss = 0.3049, Accuracy = 93.15%\n",
      "ResNet Epoch 34: Loss = 0.2979, Accuracy = 93.35%\n",
      "ResNet Epoch 35: Loss = 0.3053, Accuracy = 93.11%\n",
      "ResNet Epoch 36: Loss = 0.3027, Accuracy = 93.25%\n",
      "ResNet Epoch 37: Loss = 0.3031, Accuracy = 93.21%\n",
      "ResNet Epoch 38: Loss = 0.3010, Accuracy = 93.26%\n",
      "ResNet Epoch 39: Loss = 0.2964, Accuracy = 93.42%\n",
      "ResNet Epoch 40: Loss = 0.3005, Accuracy = 93.33%\n",
      "ResNet Epoch 41: Loss = 0.2985, Accuracy = 93.40%\n",
      "ResNet Epoch 42: Loss = 0.2925, Accuracy = 93.55%\n",
      "ResNet Epoch 43: Loss = 0.2914, Accuracy = 93.60%\n",
      "ResNet Epoch 44: Loss = 0.2920, Accuracy = 93.58%\n",
      "ResNet Epoch 45: Loss = 0.2909, Accuracy = 93.64%\n",
      "ResNet Epoch 46: Loss = 0.2927, Accuracy = 93.60%\n",
      "ResNet Epoch 47: Loss = 0.2886, Accuracy = 93.69%\n",
      "ResNet Epoch 48: Loss = 0.2882, Accuracy = 93.69%\n",
      "ResNet Epoch 49: Loss = 0.2894, Accuracy = 93.66%\n",
      "ResNet Epoch 50: Loss = 0.2890, Accuracy = 93.68%\n",
      "ResNet Epoch 51: Loss = 0.2911, Accuracy = 93.61%\n",
      "ResNet Epoch 52: Loss = 0.2807, Accuracy = 94.00%\n",
      "ResNet Epoch 53: Loss = 0.2853, Accuracy = 93.84%\n",
      "ResNet Epoch 54: Loss = 0.2880, Accuracy = 93.72%\n",
      "ResNet Epoch 55: Loss = 0.2820, Accuracy = 93.94%\n",
      "ResNet Epoch 56: Loss = 0.2852, Accuracy = 93.83%\n",
      "ResNet Epoch 57: Loss = 0.2811, Accuracy = 93.97%\n",
      "ResNet Epoch 58: Loss = 0.2867, Accuracy = 93.83%\n",
      "ResNet Epoch 59: Loss = 0.2827, Accuracy = 93.92%\n",
      "ResNet Epoch 60: Loss = 0.2789, Accuracy = 94.05%\n",
      "ResNet Epoch 61: Loss = 0.2856, Accuracy = 93.80%\n",
      "ResNet Epoch 62: Loss = 0.2821, Accuracy = 93.98%\n",
      "ResNet Epoch 63: Loss = 0.2815, Accuracy = 93.93%\n",
      "ResNet Epoch 64: Loss = 0.2800, Accuracy = 94.00%\n",
      "ResNet Epoch 65: Loss = 0.2807, Accuracy = 94.01%\n",
      "ResNet Epoch 66: Loss = 0.2789, Accuracy = 94.05%\n",
      "ResNet Epoch 67: Loss = 0.2817, Accuracy = 93.98%\n",
      "ResNet Epoch 68: Loss = 0.2752, Accuracy = 94.14%\n",
      "ResNet Epoch 69: Loss = 0.2735, Accuracy = 94.22%\n",
      "ResNet Epoch 70: Loss = 0.2810, Accuracy = 93.96%\n",
      "ResNet Epoch 71: Loss = 0.2791, Accuracy = 93.99%\n",
      "ResNet Epoch 72: Loss = 0.2752, Accuracy = 94.14%\n",
      "ResNet Epoch 73: Loss = 0.2788, Accuracy = 94.02%\n",
      "ResNet Epoch 74: Loss = 0.2768, Accuracy = 94.08%\n",
      "ResNet Epoch 75: Loss = 0.2739, Accuracy = 94.20%\n",
      "ResNet Epoch 76: Loss = 0.2748, Accuracy = 94.15%\n",
      "ResNet Epoch 77: Loss = 0.2789, Accuracy = 94.00%\n",
      "ResNet Epoch 78: Loss = 0.2788, Accuracy = 94.08%\n",
      "ResNet Epoch 79: Loss = 0.2725, Accuracy = 94.27%\n",
      "ResNet Epoch 80: Loss = 0.2761, Accuracy = 94.13%\n",
      "ResNet Epoch 81: Loss = 0.2767, Accuracy = 94.13%\n",
      "ResNet Epoch 82: Loss = 0.2728, Accuracy = 94.21%\n",
      "ResNet Epoch 83: Loss = 0.2734, Accuracy = 94.20%\n",
      "ResNet Epoch 84: Loss = 0.2741, Accuracy = 94.19%\n",
      "ResNet Epoch 85: Loss = 0.2712, Accuracy = 94.31%\n",
      "ResNet Epoch 86: Loss = 0.2746, Accuracy = 94.15%\n",
      "ResNet Epoch 87: Loss = 0.2765, Accuracy = 94.08%\n",
      "ResNet Epoch 88: Loss = 0.2705, Accuracy = 94.27%\n",
      "ResNet Epoch 89: Loss = 0.2739, Accuracy = 94.17%\n",
      "ResNet Epoch 90: Loss = 0.2736, Accuracy = 94.20%\n",
      "ResNet Epoch 91: Loss = 0.2712, Accuracy = 94.27%\n",
      "ResNet Epoch 92: Loss = 0.2714, Accuracy = 94.29%\n",
      "ResNet Epoch 93: Loss = 0.2714, Accuracy = 94.30%\n",
      "ResNet Epoch 94: Loss = 0.2743, Accuracy = 94.14%\n",
      "ResNet Epoch 95: Loss = 0.2708, Accuracy = 94.23%\n",
      "ResNet Epoch 96: Loss = 0.2734, Accuracy = 94.19%\n",
      "ResNet Epoch 97: Loss = 0.2719, Accuracy = 94.29%\n",
      "ResNet Epoch 98: Loss = 0.2676, Accuracy = 94.37%\n",
      "ResNet Epoch 99: Loss = 0.2694, Accuracy = 94.33%\n",
      "ResNet Epoch 100: Loss = 0.2704, Accuracy = 94.28%\n",
      "ResNet Epoch 101: Loss = 0.2746, Accuracy = 94.15%\n",
      "ResNet Epoch 102: Loss = 0.2699, Accuracy = 94.33%\n",
      "ResNet Epoch 103: Loss = 0.2692, Accuracy = 94.36%\n",
      "ResNet Epoch 104: Loss = 0.2718, Accuracy = 94.22%\n",
      "ResNet Epoch 105: Loss = 0.2701, Accuracy = 94.30%\n",
      "ResNet Epoch 106: Loss = 0.2701, Accuracy = 94.33%\n",
      "ResNet Epoch 107: Loss = 0.2715, Accuracy = 94.23%\n",
      "ResNet Epoch 108: Loss = 0.2679, Accuracy = 94.38%\n",
      "ResNet Epoch 109: Loss = 0.2648, Accuracy = 94.48%\n",
      "ResNet Epoch 110: Loss = 0.2726, Accuracy = 94.29%\n",
      "ResNet Epoch 111: Loss = 0.2710, Accuracy = 94.27%\n",
      "ResNet Epoch 112: Loss = 0.2675, Accuracy = 94.36%\n",
      "ResNet Epoch 113: Loss = 0.2692, Accuracy = 94.32%\n",
      "ResNet Epoch 114: Loss = 0.2672, Accuracy = 94.39%\n",
      "ResNet Epoch 115: Loss = 0.2680, Accuracy = 94.35%\n",
      "ResNet Epoch 116: Loss = 0.2700, Accuracy = 94.32%\n",
      "ResNet Epoch 117: Loss = 0.2686, Accuracy = 94.33%\n",
      "ResNet Epoch 118: Loss = 0.2695, Accuracy = 94.36%\n",
      "ResNet Epoch 119: Loss = 0.2652, Accuracy = 94.44%\n",
      "ResNet Epoch 120: Loss = 0.2674, Accuracy = 94.39%\n",
      "ResNet Epoch 121: Loss = 0.2692, Accuracy = 94.37%\n",
      "ResNet Epoch 122: Loss = 0.2736, Accuracy = 94.20%\n",
      "ResNet Epoch 123: Loss = 0.2663, Accuracy = 94.42%\n",
      "ResNet Epoch 124: Loss = 0.2625, Accuracy = 94.55%\n",
      "ResNet Epoch 125: Loss = 0.2673, Accuracy = 94.41%\n",
      "ResNet Epoch 126: Loss = 0.2677, Accuracy = 94.36%\n",
      "ResNet Epoch 127: Loss = 0.2701, Accuracy = 94.31%\n",
      "ResNet Epoch 128: Loss = 0.2668, Accuracy = 94.43%\n",
      "ResNet Epoch 129: Loss = 0.2637, Accuracy = 94.51%\n",
      "ResNet Epoch 130: Loss = 0.2659, Accuracy = 94.42%\n",
      "ResNet Epoch 131: Loss = 0.2682, Accuracy = 94.38%\n",
      "ResNet Epoch 132: Loss = 0.2650, Accuracy = 94.47%\n",
      "ResNet Epoch 133: Loss = 0.2684, Accuracy = 94.39%\n",
      "ResNet Epoch 134: Loss = 0.2679, Accuracy = 94.39%\n",
      "ResNet Epoch 135: Loss = 0.2644, Accuracy = 94.47%\n",
      "ResNet Epoch 136: Loss = 0.2653, Accuracy = 94.46%\n",
      "ResNet Epoch 137: Loss = 0.2668, Accuracy = 94.42%\n",
      "ResNet Epoch 138: Loss = 0.2684, Accuracy = 94.35%\n",
      "ResNet Epoch 139: Loss = 0.2647, Accuracy = 94.51%\n",
      "ResNet Epoch 140: Loss = 0.2646, Accuracy = 94.48%\n",
      "ResNet Epoch 141: Loss = 0.2644, Accuracy = 94.53%\n",
      "ResNet Epoch 142: Loss = 0.2682, Accuracy = 94.38%\n",
      "ResNet Epoch 143: Loss = 0.2664, Accuracy = 94.46%\n",
      "ResNet Epoch 144: Loss = 0.2620, Accuracy = 94.58%\n",
      "ResNet Epoch 145: Loss = 0.2618, Accuracy = 94.57%\n",
      "ResNet Epoch 146: Loss = 0.2652, Accuracy = 94.44%\n",
      "ResNet Epoch 147: Loss = 0.2662, Accuracy = 94.43%\n",
      "ResNet Epoch 148: Loss = 0.2650, Accuracy = 94.45%\n",
      "ResNet Epoch 149: Loss = 0.2656, Accuracy = 94.45%\n",
      "ResNet Epoch 150: Loss = 0.2697, Accuracy = 94.31%\n",
      "ResNet Epoch 151: Loss = 0.2642, Accuracy = 94.50%\n",
      "ResNet Epoch 152: Loss = 0.2623, Accuracy = 94.53%\n",
      "ResNet Epoch 153: Loss = 0.2623, Accuracy = 94.53%\n",
      "ResNet Epoch 154: Loss = 0.2644, Accuracy = 94.49%\n",
      "ResNet Epoch 155: Loss = 0.2664, Accuracy = 94.42%\n",
      "ResNet Epoch 156: Loss = 0.2644, Accuracy = 94.47%\n",
      "ResNet Epoch 157: Loss = 0.2638, Accuracy = 94.52%\n",
      "ResNet Epoch 158: Loss = 0.2627, Accuracy = 94.54%\n",
      "ResNet Epoch 159: Loss = 0.2623, Accuracy = 94.55%\n",
      "ResNet Epoch 160: Loss = 0.2676, Accuracy = 94.41%\n",
      "ResNet Epoch 161: Loss = 0.2620, Accuracy = 94.57%\n",
      "ResNet Epoch 162: Loss = 0.2614, Accuracy = 94.56%\n",
      "ResNet Epoch 163: Loss = 0.2640, Accuracy = 94.51%\n",
      "ResNet Epoch 164: Loss = 0.2676, Accuracy = 94.43%\n",
      "ResNet Epoch 165: Loss = 0.2659, Accuracy = 94.49%\n",
      "ResNet Epoch 166: Loss = 0.2652, Accuracy = 94.48%\n",
      "ResNet Epoch 167: Loss = 0.2635, Accuracy = 94.53%\n",
      "ResNet Epoch 168: Loss = 0.2625, Accuracy = 94.54%\n",
      "ResNet Epoch 169: Loss = 0.2635, Accuracy = 94.52%\n",
      "ResNet Epoch 170: Loss = 0.2641, Accuracy = 94.48%\n",
      "ResNet Epoch 171: Loss = 0.2641, Accuracy = 94.50%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     19\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/folder.py:230\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[0;32m--> 230\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/folder.py:269\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/folder.py:249\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    248\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/PIL/Image.py:922\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m    876\u001b[0m ):\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/PIL/ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(train_data.classes))\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader.dataset)\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"ResNet Epoch {epoch+1}: Loss = {avg_loss:.4f}, Accuracy = {accuracy:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
