{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "source_dir = \"\"\n",
    "train_dir = \"\"\n",
    "test_dir = \"\"\n",
    "test_ratio = 0.2 \n",
    "\n",
    "for split_dir in [train_dir, test_dir]:\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "for class_dir in os.listdir(source_dir):\n",
    "    class_path = os.path.join(source_dir, class_dir)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    images = list(Path(class_path).glob(\"*.*\"))\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    test_size = int(len(images) * test_ratio)\n",
    "    test_images = images[:test_size]\n",
    "    train_images = images[test_size:]\n",
    "\n",
    "    train_class_dir = os.path.join(train_dir, class_dir)\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    for img in train_images:\n",
    "        shutil.copy(img, os.path.join(train_class_dir, img.name))\n",
    "\n",
    "    test_class_dir = os.path.join(test_dir, class_dir)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "    for img in test_images:\n",
    "        shutil.copy(img, os.path.join(test_class_dir, img.name))\n",
    "\n",
    "print(\"Dataset split complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path('')\n",
    "\n",
    "bad_files = []\n",
    "\n",
    "for img_path in dataset_dir.rglob(\"*.*\"):\n",
    "    if img_path.is_file():\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img.verify()\n",
    "        except (UnidentifiedImageError, OSError):\n",
    "            bad_files.append(img_path)\n",
    "\n",
    "for bad_file in bad_files:\n",
    "    print(f\"Removing corrupted image: {bad_file}\")\n",
    "    os.remove(bad_file)\n",
    "\n",
    "print(f\"Removed {len(bad_files)} bad files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root='', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = resnet18(num_classes=len(dataset.classes))\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):\n",
    "    for inputs, labels in dataloader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU version\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root='/Users/ravanryj/Desktop/team-00-project/Hezi_Jiang_44/archive/', transform=transform)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = resnet18(num_classes=len(dataset.classes))\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Grayscale fix\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1} complete â€” Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training finished!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
